# Boas vindas ao **books_word_cloud!**

Para executar o projeto, observe as orienta√ß√µes descritas a seguir, e se tiver qualquer d√∫vida, sugest√£o, contribui√ß√£o, considere abrir uma issue ou entrar em contato. üöÄ

Aqui voc√™ vai encontrar os detalhes de como est√° estruturado e foi desenvolvido o projeto.

# <a id='topicos'>T√≥picos</a>
- [Desenvolvimento](#desenvolvimento)
  - [Objetivo](#objetivo)
  - [Estrutura do projeto](#estrutura)
  - [Tecnologias utilizadas](#tecnologias)
- [Orienta√ß√µes](#orientacoes)
  - [Executando o projeto](#execucao)
    - [1. Sem o docker](#sem-docker)
    - [2. Com o docker](#com-docker)
  - [Linter](#linter)
  - [Testes](#testes)
- [Implementa√ß√µes](#implementacoes)
  - [Contextualizando](#contextualizando)
  - [Vis√£o do app](#consumindo)
- [Pr√≥ximos passos](#next)

# <a id='desenvolvimento'>[Desenvolvimento](#topicos)</a>

<strong><a id='objetivo'>[Objetivo](#topicos)</a></strong>

  O **objetivo** √© criar uma nuvem de palavras com o conte√∫do de alguns livros populares obtidos pela API [Gutendex](https://gutendex.com/).
  
  Para isso, foi feita a leitura e transforma√ß√£o dos dados com o `Pyspark`, ferramenta que integra t√©cnicas de `machine learning` (tokeniza√ß√£o, feature engineering, etc..) com o processamento de big data; e o `streamlit` solu√ß√£o em python geradora de interface gr√°fica do usu√°rio.

  ---

<strong><a id='estrutura'>[Estrutura do projeto](#topicos)</a></strong>

* **Na pasta [src](src) est√£o os diret√≥rios:**
  * **[configs](src/configs)** com os arquivos de configura√ß√£o da execu√ß√£o do c√≥digo-fonte;
  * **[controllers](src/controllers)** com a [camada](src/controllers/books.py) que orquestra o aplicativo;
  * **[data](src/data)** com [os arquivos de texto](src/data/raw_content) contendo os conte√∫dos dos livros obtidos pelo [Gutendex](https://gutendex.com/);
  * **[models](src/models)** com a [camada](src/models/books.py) que interage com a fonte de dados do aplicativo;
  * **[services](src/services)** com a [camada](src/services/books.py) que aplica as transforma√ß√µes dos dados e cria√ß√£o da nuvem de palavras;
  * **[utils](src/utils)** com o [arquivo](src/utils/text_search.py) utilit√°rio na execu√ß√£o do c√≥digo fonte;
  * **[views](src/views)** com a [camada](src/views/books.py) que gera os elementos da interface gr√°fica do aplicativo.
* **E o arquivo:**
  * **[main.py](src/main.py)** com a classe **Main**, executora do c√≥digo-fonte da aplica√ß√£o.
* **Na pasta [tests](tests) est√£o os arquivos com os testes das respectivas camadas do c√≥digo-fonte.**
* **E os arquivos:**
  * **[docker-compose.yml](docker-compose.yml)** arquivo que possibilita a execu√ß√£o da aplica√ß√£o, orquestrando as imagens docker do `spark` e `python`;
  * **[Dockerfile.Python](Dockerfile.Python)** container docker do `python` com as especifica√ß√µes necess√°rias para a aplica√ß√£o;
  * **[requirements.txt](requirements.txt)** arquivo com as depend√™ncias necess√°rias e utilizadas para execu√ß√£o do projeto;
  * **[tox.ini](tox.ini)** arquivo com a configura√ß√£o de uso da [an√°lise est√°tica do c√≥digo](#linter).

<strong><a id='tecnologias'>[Tecnologias utilizadas](#topicos)</a></strong>

  O projeto foi desenvolvido em Python, desde a interface gr√°fica at√© a intera√ß√£o com a fonte dos dados.

  As solu√ß√µes utilizadas foram:

* **[Pyspark](https://spark.apache.org/docs/latest/api/python/index.html):**
  * Interface para execu√ß√£o do Spark em `python`, com todas as solu√ß√µes de processamento de dados da ferramenta;
* **[Streamlit](https://streamlit.io/):**
  * Framework do `python` para constru√ß√£o amig√°vel de aplicativos interativos;
* **[Wordcloud](http://amueller.github.io/word_cloud/):**
  * Biblioteca `python` para cria√ß√£o de nuvem de palavras de forma simples.

>No arquivo de depend√™ncias, **[requirements.txt](requirements.txt)**, √© listada outras depend√™ncias acess√≥rias √† essas bibliotecas e tamb√©m utilizadas para **[an√°lise do c√≥digo](#linter)** e **[testes da aplica√ß√£o](#testes)**.
    
# <a id='orientacoes'>[Orienta√ß√µes](#topicos)</a>

<strong><a id='execucao'>[Executando o projeto](#topicos)</a></strong>

A aplica√ß√£o foi pensada para ser testada com o `Docker`, visando torn√°-la o mais agn√≥stica poss√≠vel.

√â poss√≠vel sua execu√ß√£o sem a ferramenta, com sugest√µes para os dois cen√°rios abaixo:

>**IMPORTANTE**<br/>Independente da escolha, ap√≥s clonar o projeto, entre com seu terminal na pasta criada:<br/>`cd books_word_cloud`<br/>**Todas orienta√ß√µes abaixo, tem essa pasta como refer√™ncia.**

### <strong><a id='sem-docker'>[1. Execu√ß√£o sem o docker:](#topicos)</a></strong>

Nesse cen√°rio, √© necess√°rio que sua m√°quina possua instalado: i. o `spark` na vers√£o 3.4.0; ii. o kit de desenvolvimento java (`java jdk`) na vers√£o 8 ou superior; iii. e o `python`. Sobre essas ferramentas:

#### **i. Spark e jdk:**

  **√â fundamental o uso das vers√µes recomendadas do spark e java jdk** para integra√ß√£o com sucesso do spark<>pyspark. **Recomenda-se o jdk-11**, vers√£o utilizada na constru√ß√£o da aplica√ß√£o. 

  **N√£o foi testado, mas caso use uma vers√£o spark superior √† 3.0 localmente, n√£o espera-se incompatibilidade na execu√ß√£o do aplicativo.** Nesse cen√°rio, modifique a vers√£o do pyspark no arquivo requirements.txt antes do pr√≥ximo passo.

#### **ii. Python:** 
  
  O projeto foi constru√≠do com o python na vers√£o 3.10, por√©m **n√£o se espera indisponibilidades com sua execu√ß√£o √† partir da vers√£o 3.4.** 

  **Qualquer incompatibilidade com a vers√£o da sua m√°quina por favor informe.**

  Ainda, √© recomendada a instala√ß√£o pr√©via do gerenciador de pacotes `pip` para os passos a seguir:

  >**(Recomendado)** **Utilizar um ambiente virtual** com os seguintes comandos (nome `words_venv` j√° considerado na ferramenta de [lint](#lint)):
  ```shell
  # cria o ambiente com o nome words_venv:
  python3 -m venv words_venv 
  # ativa o ambiente em terminais Linux e Mac:
  source words_venv/bin/activate
  # ativa o ambiente em terminal Windows (cmd):
  words_venv\bin\activate
  ```
  >1.**Instalar depend√™ncias do projeto:**
  ```ps1
  pip install -r requirements.txt
  ```
  >2.**Setar PYTHONPATH:**
  ```shell
  export PYTHONPATH=./
  ```
  >3.**Executar projeto (na pasta criada com o clone):**
  ```bash
  streamlit run src/main.py
  ```
  >4.**Executar projeto instanciando a classe Main (na pasta criada com o clone):**
  ```python
  from src.main import Main

  Main().run()
  ```
  >5.**Executando testes (na pasta criada com o clone):**
  ```ps1
  pytest -v
  pytest --cov=tests/
  ```

### <strong><a id='com-docker'>[2. Execu√ß√£o com o docker:](#topicos)</a></strong>

>**IMPORTANTE**<br/>Nesse cen√°rio recomenda-se utilizar as vers√µes a seguir das ferramentas docker:<br/>`docker:25.0.3`  `docker-compose:1.29.2` <br/>**Verifique suas vers√µes com os comandos:** <br/>`docker version` e `docker-compose -v`

### Usando docker-compose para orquestrar imagens:
Com o docker-compose n√£o √© necess√°rio ter o `python`, `java` ou `spark` instalados localmente. Nessa op√ß√£o, a execu√ß√£o da aplica√ß√£o ser√° dispon√≠vel na porta `8501` do servidor local.

Passos para sua inicializa√ß√£o:
```bash
# na raiz do projeto, inicie os containers:
docker-compose up -d
# confirme que est√£o de p√©:
docker-compose ps
# caso tenha erro, ver logs do problema do container:
docker-compose logs book-app # exemplo com container python
# vendo logs de todos os containers:
docker-compose logs
# com a corre√ß√£o do erro, derrube os containers:
docker-compose down
# derrubando os containers for√ßando a limpeza dos seus volumes:
docker-compose down -v
# reiniciando containers for√ßando recria√ß√£o de um deles:
docker-compose up -d --force-recreate book-app
# reiniciando containers for√ßando o rebuild das imagens:
docker-compose up --build 
```

Com o funcionamento dos containers, √© poss√≠vel executar os arquivos do projeto dessa forma:
```bash
# executando arquivo do container:
docker exec <container_name_or_id> python /caminho/para/seu/arquivo.py
# exemplo de execu√ß√£o dos testes do c√≥digo:
docker exec book-app pytest -v
# executando arquivos dentro do container:
docker exec -it <container_name> bash
# ex para o cluster do app:
docker exec -it book-app
```
>**IMPORTANTE**<br/>Nos logs de inicializa√ß√£o do container √© mostrada onde est√° localizada o execut√°vel java (JAVA_HOME) do container spark. Caso esse valor seja diferente do atual no docker-compose, modifique-o para execu√ß√£o com √™xito do projeto.
```dockerfile
environment:
  ...

  - JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 # valor atual.
```

<strong><a id='linter'>[Linter](#topicos)</a></strong>

Foi utilizado o [**flake8**](https://flake8.pycqa.org/en/latest/) para fazer a an√°lise est√°tica do c√≥digo visando garantir as boas pr√°ticas e legibilidade do c√≥digo.

>Considere instalar as configura√ß√µes do flake8 no seu editor de texto para contribui√ß√µes no projeto.

Para executar o `flake8`, no seu terminal Mac ou Linux:
```bash
# na raiz do projeto:
flake8
# analisando um diret√≥rio em espec√≠fico:
flake8 src/
# analisando um arquivo em espec√≠fico:
flake8 src/main.py
```

<strong><a id='testes'>[Testes](#topicos)</a></strong>

Foi utilizado o **[pytest](https://docs.pytest.org/en/8.0.x/)** e **[unittest](https://docs.python.org/3/library/unittest.html)** para constru√ß√£o dos testes (de integra√ß√£o, unit√°rios e de carga atualmente) da aplica√ß√£o.

Mais detalhes na documenta√ß√£o dessas bibliotecas.

### Mande seu feedback sobre o projeto!

Se estiver a vontade, clone o reposit√≥rio e, seja com ou sem o Docker, execute, veja o deploy e me ajude a melhorar este projeto! Seu feedback ser√° super bem vindo!

# <a id='implementacoes'>[Implementa√ß√µes](#topicos)</a>

<strong><a id='contextualizando'>[Contextualizando](#topicos)</a></strong>

  A nuvem de palavras √© uma das ferramentas mais populares na an√°lise de sentimento de textos, em especial da t√©cnica de contagem de palavras.

  Para mostrar o potencial da solu√ß√£o, desenvolveu-se essa aplica√ß√£o que constr√≥i uma nuvem de palavras com `python` e `pyspark`, com as 50 principais palavras de livros famosos dispon√≠veis na API Gutendex.
  
<strong><a id='consumindo'>[Vis√£o do app](#topicos)</a></strong>

  Para execu√ß√£o do projeto (como descrito [nessa se√ß√£o](#sem-docker)), execute o comando abaixo na raiz do projeto clonado:

  ```bash
  streamlit run src/main.py  
  ```
  
  No seu servidor local, na porta `8501`, a aplica√ß√£o deve ficar dispon√≠vel, como abaixo:

  ![books-app gif](docs/book-app.gif)

# <a id='next'>[Pr√≥ximos passos](#topicos)</a>

  As features mapeadas s√£o:

  * **Fazer o deploy da aplica√ß√£o**;

  * **Ampliar cen√°rios de testes** garantindo o design da aplica√ß√£o;

  * **Construir uma esteira de CI/CD** para garantir a governan√ßa das implementa√ß√µes do projeto;

  * **Orquestrar o ambiente com Kubernetes**, adicionando uma op√ß√£o de disponibilidade da execu√ß√£o do projeto;

  * **Gerenciar os containers com helm**, adicionando uma op√ß√£o din√¢mica de disponibilidade da execu√ß√£o do projeto.

---
